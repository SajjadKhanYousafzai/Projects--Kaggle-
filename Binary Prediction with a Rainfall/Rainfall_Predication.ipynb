{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee4a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "# Set styling for plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({'font.size': 12, 'axes.labelsize': 14, 'axes.titlesize': 16})\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84415028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "df_train = pd.read_csv(\"./data/train.csv\")\n",
    "df_test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedf026d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (2190, 13)\n",
      "Test data shape: (730, 12)\n",
      "\n",
      "--- Missing Values ---\n",
      "id               0\n",
      "day              0\n",
      "pressure         0\n",
      "maxtemp          0\n",
      "temparature      0\n",
      "mintemp          0\n",
      "dewpoint         0\n",
      "humidity         0\n",
      "cloud            0\n",
      "sunshine         0\n",
      "winddirection    0\n",
      "windspeed        0\n",
      "rainfall         0\n",
      "dtype: int64\n",
      "\n",
      "--- Duplicate Rows ---\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Display basic info\n",
    "print(f\"Train data shape: {df_train.shape}\")\n",
    "print(f\"Test data shape: {df_test.shape}\")\n",
    "\n",
    "# Check missing values\n",
    "print(\"\\n--- Missing Values ---\")\n",
    "print(df_train.isnull().sum())\n",
    "print(\"\\n--- Duplicate Rows ---\")\n",
    "print(f\"Number of duplicate rows: {df_train.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca8f3cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Statistical Summary ---\n",
      "                id          day     pressure      maxtemp  temparature  \\\n",
      "count  2190.000000  2190.000000  2190.000000  2190.000000  2190.000000   \n",
      "mean   1094.500000   179.948402  1013.602146    26.365799    23.953059   \n",
      "std     632.342866   105.203592     5.655366     5.654330     5.222410   \n",
      "min       0.000000     1.000000   999.000000    10.400000     7.400000   \n",
      "25%     547.250000    89.000000  1008.600000    21.300000    19.300000   \n",
      "50%    1094.500000   178.500000  1013.000000    27.800000    25.500000   \n",
      "75%    1641.750000   270.000000  1017.775000    31.200000    28.400000   \n",
      "max    2189.000000   365.000000  1034.600000    36.000000    31.500000   \n",
      "\n",
      "           mintemp     dewpoint     humidity        cloud     sunshine  \\\n",
      "count  2190.000000  2190.000000  2190.000000  2190.000000  2190.000000   \n",
      "mean     22.170091    20.454566    82.036530    75.721918     3.744429   \n",
      "std       5.059120     5.288406     7.800654    18.026498     3.626327   \n",
      "min       4.000000    -0.300000    39.000000     2.000000     0.000000   \n",
      "25%      17.700000    16.800000    77.000000    69.000000     0.400000   \n",
      "50%      23.850000    22.150000    82.000000    83.000000     2.400000   \n",
      "75%      26.400000    25.000000    88.000000    88.000000     6.800000   \n",
      "max      29.800000    26.700000    98.000000   100.000000    12.100000   \n",
      "\n",
      "       winddirection    windspeed     rainfall  \n",
      "count    2190.000000  2190.000000  2190.000000  \n",
      "mean      104.863151    21.804703     0.753425  \n",
      "std        80.002416     9.898659     0.431116  \n",
      "min        10.000000     4.400000     0.000000  \n",
      "25%        40.000000    14.125000     1.000000  \n",
      "50%        70.000000    20.500000     1.000000  \n",
      "75%       200.000000    27.900000     1.000000  \n",
      "max       300.000000    59.500000     1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Statistical summary\n",
    "print(\"\\n--- Statistical Summary ---\")\n",
    "print(df_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c3bb214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Target Variable Distribution ---\n",
      "rainfall\n",
      "1    75.342466\n",
      "0    24.657534\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Target variable distribution\n",
    "print(\"\\n--- Target Variable Distribution ---\")\n",
    "print(df_train[\"rainfall\"].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9b7b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify outliers using IQR method\n",
    "def identify_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Identify numerical features\n",
    "numerical_features = ['pressure', 'maxtemp', 'temparature', 'mintemp',\n",
    "                      'dewpoint', 'humidity', 'cloud', 'sunshine', \n",
    "                      'winddirection', 'windspeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5508adb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Outlier Analysis ---\n",
      "pressure: 4 outliers (0.18%)\n",
      "maxtemp: 0 outliers (0.00%)\n",
      "temparature: 0 outliers (0.00%)\n",
      "mintemp: 1 outliers (0.05%)\n",
      "dewpoint: 26 outliers (1.19%)\n",
      "humidity: 28 outliers (1.28%)\n",
      "cloud: 129 outliers (5.89%)\n",
      "sunshine: 0 outliers (0.00%)\n",
      "winddirection: 0 outliers (0.00%)\n",
      "windspeed: 28 outliers (1.28%)\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers in each numerical feature\n",
    "print(\"\\n--- Outlier Analysis ---\")\n",
    "outlier_stats = {}\n",
    "for feature in numerical_features:\n",
    "    outliers, lower, upper = identify_outliers(df_train, feature)\n",
    "    outlier_percent = len(outliers) / len(df_train) * 100\n",
    "    outlier_stats[feature] = {\n",
    "        \"count\": len(outliers),\n",
    "        \"percentage\": outlier_percent,\n",
    "        \"lower_bound\": lower,\n",
    "        \"upper_bound\": upper\n",
    "    }\n",
    "    print(f\"{feature}: {len(outliers)} outliers ({outlier_percent:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec93d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Correlation Analysis ---\n",
      "Highly correlated feature pairs:\n",
      "pressure & maxtemp: -0.800\n",
      "pressure & temparature: -0.817\n",
      "pressure & mintemp: -0.814\n",
      "pressure & dewpoint: -0.817\n",
      "maxtemp & temparature: 0.983\n",
      "maxtemp & mintemp: 0.966\n",
      "maxtemp & dewpoint: 0.907\n",
      "temparature & mintemp: 0.987\n",
      "temparature & dewpoint: 0.934\n",
      "mintemp & dewpoint: 0.941\n",
      "cloud & sunshine: -0.805\n"
     ]
    }
   ],
   "source": [
    "# Feature correlation analysis\n",
    "print(\"\\n--- Feature Correlation Analysis ---\")\n",
    "correlation_matrix = df_train[numerical_features + ['rainfall']].corr()\n",
    "high_corr_features = []\n",
    "\n",
    "# Find highly correlated feature pairs (excluding self-correlations)\n",
    "print(\"Highly correlated feature pairs:\")\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:  # Threshold for high correlation\n",
    "            print(f\"{correlation_matrix.columns[i]} & {correlation_matrix.columns[j]}: {correlation_matrix.iloc[i, j]:.3f}\")\n",
    "            high_corr_features.append((correlation_matrix.columns[i], correlation_matrix.columns[j], correlation_matrix.iloc[i, j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f3d3bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature correlation with target (rainfall):\n",
      "rainfall         1.000000\n",
      "cloud            0.641191\n",
      "humidity         0.454213\n",
      "windspeed        0.111625\n",
      "dewpoint         0.081965\n",
      "winddirection   -0.006939\n",
      "mintemp         -0.026841\n",
      "temparature     -0.049660\n",
      "pressure        -0.049886\n",
      "maxtemp         -0.079304\n",
      "sunshine        -0.555287\n",
      "Name: rainfall, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Feature correlation with target\n",
    "target_correlation = correlation_matrix['rainfall'].sort_values(ascending=False)\n",
    "print(\"\\nFeature correlation with target (rainfall):\")\n",
    "print(target_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b326d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing function\n",
    "def preprocess_data(df, is_train=True):\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    processed_df = df.copy()\n",
    "    \n",
    "    # Handle outliers (for training data only)\n",
    "    if is_train:\n",
    "        for feature in numerical_features:\n",
    "            stats = outlier_stats[feature]\n",
    "            # Cap outliers at bounds instead of removing them\n",
    "            processed_df[feature] = np.where(\n",
    "                processed_df[feature] < stats[\"lower_bound\"],\n",
    "                stats[\"lower_bound\"],\n",
    "                processed_df[feature]\n",
    "            )\n",
    "            processed_df[feature] = np.where(\n",
    "                processed_df[feature] > stats[\"upper_bound\"],\n",
    "                stats[\"upper_bound\"],\n",
    "                processed_df[feature]\n",
    "            )\n",
    "    \n",
    "    # Standardize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    if is_train:\n",
    "        processed_df[numerical_features] = scaler.fit_transform(processed_df[numerical_features])\n",
    "        # Save the scaler for later use with test data\n",
    "        with open(\"scaler.pkl\", \"wb\") as f:\n",
    "            pickle.dump(scaler, f)\n",
    "    else:\n",
    "        # Load the scaler fitted on training data\n",
    "        try:\n",
    "            with open(\"scaler.pkl\", \"rb\") as f:\n",
    "                scaler = pickle.load(f)\n",
    "            processed_df[numerical_features] = scaler.transform(processed_df[numerical_features])\n",
    "        except FileNotFoundError:\n",
    "            print(\"Scaler file not found. Using new scaler instance.\")\n",
    "            processed_df[numerical_features] = scaler.fit_transform(processed_df[numerical_features])\n",
    "    \n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "947bae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preprocessing Data ---\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "print(\"\\n--- Preprocessing Data ---\")\n",
    "df_train_processed = preprocess_data(df_train, is_train=True)\n",
    "df_test_processed = preprocess_data(df_test, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6314e6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Selection using Random Forest ---\n"
     ]
    }
   ],
   "source": [
    "# Feature selection using Random Forest feature importance\n",
    "print(\"\\n--- Feature Selection using Random Forest ---\")\n",
    "X = df_train_processed[numerical_features]\n",
    "y = df_train['rainfall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa3d0750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Feature  Importance\n",
      "6          cloud    0.291328\n",
      "7       sunshine    0.186434\n",
      "5       humidity    0.097538\n",
      "4       dewpoint    0.067204\n",
      "1        maxtemp    0.066039\n",
      "0       pressure    0.065979\n",
      "9      windspeed    0.063994\n",
      "3        mintemp    0.060184\n",
      "2    temparature    0.057388\n",
      "8  winddirection    0.043913\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest to assess feature importance\n",
    "rf_selector = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_selector.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_selector.feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': numerical_features,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "083fea91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features: ['cloud', 'sunshine', 'humidity', 'dewpoint', 'maxtemp', 'pressure', 'windspeed', 'mintemp', 'temparature']\n"
     ]
    }
   ],
   "source": [
    "# Select top features (above certain threshold)\n",
    "importance_threshold = 0.05  # Features with importance > 5%\n",
    "selected_features = feature_importance[feature_importance['Importance'] > importance_threshold]['Feature'].tolist()\n",
    "print(f\"\\nSelected features: {selected_features}\")\n",
    "\n",
    "# Prepare final datasets with selected features\n",
    "X_train = df_train_processed[selected_features]\n",
    "y_train = df_train['rainfall']\n",
    "X_test = df_test_processed[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a409c798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final datasets shapes ---\n",
      "Training data: (1752, 9)\n",
      "Validation data: (438, 9)\n",
      "Test data: (730, 9)\n"
     ]
    }
   ],
   "source": [
    "# Split training data into train and validation sets\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(\"\\n--- Final datasets shapes ---\")\n",
    "print(f\"Training data: {X_train_split.shape}\")\n",
    "print(f\"Validation data: {X_val.shape}\")\n",
    "print(f\"Test data: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd675b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed datasets for model training\n",
    "X_train.to_csv(\"processed_X_train.csv\", index=False)\n",
    "pd.DataFrame(y_train).to_csv(\"processed_y_train.csv\", index=False)\n",
    "X_test.to_csv(\"processed_X_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a3dd94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed data saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Save test IDs for submission file creation\n",
    "test_ids = df_test['id']\n",
    "test_ids.to_csv(\"test_ids.csv\", index=False)\n",
    "\n",
    "print(\"\\nPreprocessed data saved to CSV files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rec_sys_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
